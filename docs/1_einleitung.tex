\section{Einleitung}\label{einleitung}
Neuronale Netze sind ein weit verbreitetes Thema. Dabei wird ihnen oft mehr ``Magie''
zugesprochen als in ihnen eigentlich enthalten ist. Der Lernprozess eines neuronalen 
Netzes ist nämlich einfach ein sinnvoller Algorithmus, der auf viele Problemstellungen angewandt werden kann.
Jedoch kann jeder Algorithmus verbessert werden. Der grundlegende Algorithmus ist hierfür
der sogenannte Gradient Descent oder zu deutsch Gradienten Abstiegsverfahren. 
Dieser weißt jedoch verschiedene Probleme auf. Deshalb gibt es Optimierungsalgorithmen,
die die Fehler des grundlegenden Algorithmus verbessern wollen. Hierbei ist die Wahl 
des Optimierungsalgorithmus jedoch nicht immer eindeutig. Diese gibt es reichlich
und es ist nicht immer offensichtlich, welcher Algorithmus wo angewandt werden sollte.
Deshalb greift sich diese Arbeit drei bekannte Optimierungsalgorithmen heraus und 
evaluiert diese anhand von geeigneten Metriken. Dabei wird ein Python Programm erstellte, 
um diese Fragen beantworten zu können. Um die Problematik zu beleuchten, wird erst
in die Theorie der neuronale Netze und des Gradienten Abstiegsverfahrens eingeführt.
Anschließend werden die verschiedenen Optimierungsalgorithmen theoretisch aufgearbeitet.
Im Anschluss wird sich mit den genutzten Metriken und dem Aufbau des Programms beschäftigt.
Schlussendlich werden die Ergebnisse ausgewertet und mit der Literatur verglichen.    
